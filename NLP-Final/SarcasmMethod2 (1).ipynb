{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Sarcasm Detection Method 2"
      ],
      "metadata": {
        "id": "NX7E5jF6gRJC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AkUoNzMgL2r"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import re\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.spatial.distance import cdist\n",
        "from sklearn import metrics\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFhmxeifN95x",
        "outputId": "bc926c86-499d-4721-f544-a39ad8e64d1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigmodel = gensim.models.KeyedVectors.load_word2vec_format('/content/drive/MyDrive/SarcasmProjectNLP/GoogleNews-vectors-negative300-SLIM.bin', binary=True)"
      ],
      "metadata": {
        "id": "0r8PN4VVj5Rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notsarcasm = []     # list of non sarcastic comments\n",
        "notsarcasmtoks = []  # list of lists of tokens in the non sarcastic comments\n",
        "\n",
        "\n",
        "# reads in the non sarcasm train file and tokenizes (with or without parent comment)\n",
        "f = open('/content/drive/MyDrive/SarcasmProjectNLP/train_not_sarcasm.txt')\n",
        "# f = open('/content/drive/MyDrive/SarcasmProjectNLP/train_not_npsarcasm.txt')\n",
        "for line in f:\n",
        "    line = line.rstrip()\n",
        "    notsarcasm.append(line)    \n",
        "    line = re.sub(r\"(^| )[0-9]+($| )\", r\" \", line)  \n",
        "    addme = [t.lower() for t in line.split()]\n",
        "    notsarcasmtoks.append(addme)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "cII6rO8cgToE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list of 300-dimensional vectors per non sarcastic comment\n",
        "notsarcasmvectors = []   \n",
        "\n",
        "for h in notsarcasmtoks:\n",
        "    totvec = np.zeros(300)\n",
        "    for w in h:\n",
        "        if w.lower() in bigmodel:\n",
        "            totvec = totvec + bigmodel[w.lower()]\n",
        "    notsarcasmvectors.append(totvec)"
      ],
      "metadata": {
        "id": "PE4Z3yjZhOTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tried a variety of cluster sizes ranging from 30 to 60 for Knn\n",
        "\n",
        "# kmnews = KMeans(n_clusters=30, random_state=0)\n",
        "# kmnews = KMeans(n_clusters=40, random_state=0)\n",
        "kmnews = KMeans(n_clusters=50, random_state=0)\n",
        "# kmnews = KMeans(n_clusters=60, random_state=0)\n",
        "notsarcasmclusters = kmnews.fit_predict(notsarcasmvectors)"
      ],
      "metadata": {
        "id": "iG2mvsovhUDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sarcasm = []     # list of sarcastic comments\n",
        "sarcasmtoks = []  # list of lists of tokens in the sarcastic comments\n",
        "\n",
        "# reads in the sarcasm train file and tokenizes (with or without parent comment)\n",
        "f = open('/content/drive/MyDrive/SarcasmProjectNLP/train_sarcasm.txt')\n",
        "# f = open('/content/drive/MyDrive/SarcasmProjectNLP/train_npsarcasm.txt')\n",
        "for line in f:\n",
        "    line = line.rstrip()\n",
        "    sarcasm.append(line)    \n",
        "    line = re.sub(r\"(^| )[0-9]+($| )\", r\" \", line)\n",
        "    addme = [t.lower() for t in line.split()]\n",
        "    sarcasmtoks.append(addme)\n",
        "f.close()\n",
        "\n",
        "# list of 300-dimensional vectors per sarcastic comment\n",
        "sarcasmvectors = []      \n",
        "\n",
        "for h in sarcasmtoks:\n",
        "    totvec = np.zeros(300)\n",
        "    for w in h:\n",
        "        if w.lower() in bigmodel:\n",
        "            totvec = totvec + bigmodel[w.lower()]\n",
        "    sarcasmvectors.append(totvec)"
      ],
      "metadata": {
        "id": "uiBlVQ8AhWb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmclick = KMeans(n_clusters=50, random_state=0)  \n",
        "sarcasmclusters = kmclick.fit_predict(sarcasmvectors)  "
      ],
      "metadata": {
        "id": "8UWMkczqhrd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testtargets = []  # stores whether a test comment is sarcastic or not\n",
        "testvectors = []  # stores the vector of the test comment\n",
        "\n",
        "# reads in test file and stores the appropriate values in the lists above (with and without parent comment)\n",
        "f = open('/content/drive/MyDrive/SarcasmProjectNLP/sarcasm_test.txt')\n",
        "# f = open('/content/drive/MyDrive/SarcasmProjectNLP/npsarcasm_test.txt')\n",
        "\n",
        "for line in f:\n",
        "    line = line.rstrip()    \n",
        "    line = re.sub(r\"(^| )[0-9]+($| )\", r\" \", line)\n",
        "    if line[0] == ' ':\n",
        "      testtargets.append(1)\n",
        "    else:\n",
        "      testtargets.append(int(line[0]))\n",
        "    line = line[2:]\n",
        "    vectors = [t.lower() for t in line.split()]\n",
        "    totvec = np.zeros(300)\n",
        "    for h in vectors:\n",
        "        if h.lower() in bigmodel:\n",
        "            totvec = totvec + bigmodel[h.lower()]\n",
        "    testvectors.append(totvec)\n",
        "\n",
        "# calculates cosine distance between vectors\n",
        "\n",
        "sarcasmdistances = cdist(testvectors, sarcasmvectors)\n",
        "\n",
        "notsarcasmdistances = cdist(testvectors, notsarcasmvectors)\n",
        "\n",
        "sarcasmmins = sarcasmdistances.min(axis=1)\n",
        "\n",
        "notsarcasmmins = notsarcasmdistances.min(axis=1)\n",
        "\n",
        "predictedknn = []\n",
        "\n",
        "# predicts correct label based on the minimum cosine distance (a larger value means vectors are closer together)\n",
        "\n",
        "for i in range(len(notsarcasmmins)):\n",
        "    if notsarcasmmins[i] < sarcasmmins[i]: \n",
        "        predictedknn.append(0)\n",
        "    else:\n",
        "        predictedknn.append(1)\n",
        "\n",
        "print(metrics.classification_report(testtargets, predictedknn))"
      ],
      "metadata": {
        "id": "O-WAXzy5ht_w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8d2f24d-882d-4ac3-a2c0-7f486157642c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.54      0.54      5001\n",
            "           1       0.53      0.52      0.52      5000\n",
            "\n",
            "    accuracy                           0.53     10001\n",
            "   macro avg       0.53      0.53      0.53     10001\n",
            "weighted avg       0.53      0.53      0.53     10001\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alltargets = list(np.ones(len(sarcasmvectors)))\n",
        "alltargets.extend(np.zeros(len(notsarcasmvectors)))\n",
        "alltargets = np.array(alltargets)\n",
        "\n",
        "allvectors = sarcasmvectors + notsarcasmvectors\n",
        "\n",
        "# Using Naive Bayes on the dataset by fitting it to the training data then predicting on the test set\n",
        "\n",
        "model = GaussianNB()\n",
        "\n",
        "model.fit(allvectors, alltargets)\n",
        "\n",
        "expected = testtargets\n",
        "predicted = model.predict(testvectors)\n",
        "\n",
        "print(metrics.classification_report(expected, predicted))\n",
        "\n",
        "\n",
        "# Using LinearSVM on the dataset by fitting it to the training data then predicting on the test set\n",
        "\n",
        "lsvc = LinearSVC(dual=False, max_iter = 1000)\n",
        "\n",
        "lsvc.fit(allvectors, alltargets)\n",
        "\n",
        "expected = testtargets\n",
        "predicted = lsvc.predict(testvectors)\n",
        "\n",
        "print(metrics.classification_report(expected, predicted))\n",
        "\n",
        "# Using Logistic Regression on the dataset by fitting it to the training data then predicting on the test set\n",
        "\n",
        "logreg = LogisticRegression(max_iter = 1000)\n",
        "\n",
        "logreg.fit(allvectors, alltargets)\n",
        "\n",
        "expected = testtargets\n",
        "predicted = logreg.predict(testvectors)\n",
        "\n",
        "print(metrics.classification_report(expected, predicted))"
      ],
      "metadata": {
        "id": "8KApPrdjiNMf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2657724-4906-4500-b6a0-9b37292fe333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.09      0.16      5001\n",
            "           1       0.50      0.92      0.65      5000\n",
            "\n",
            "    accuracy                           0.51     10001\n",
            "   macro avg       0.52      0.51      0.41     10001\n",
            "weighted avg       0.52      0.51      0.41     10001\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.64      0.61      5001\n",
            "           1       0.61      0.56      0.58      5000\n",
            "\n",
            "    accuracy                           0.60     10001\n",
            "   macro avg       0.60      0.60      0.60     10001\n",
            "weighted avg       0.60      0.60      0.60     10001\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.64      0.61      5001\n",
            "           1       0.61      0.56      0.58      5000\n",
            "\n",
            "    accuracy                           0.60     10001\n",
            "   macro avg       0.60      0.60      0.60     10001\n",
            "weighted avg       0.60      0.60      0.60     10001\n",
            "\n"
          ]
        }
      ]
    }
  ]
}